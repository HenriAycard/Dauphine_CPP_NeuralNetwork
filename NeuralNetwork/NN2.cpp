//
//  NN2.cpp
//  NeuralNetwork
//
//  Created by Henri Aycard on 30/05/2021.
//  Copyright Â© 2021. All rights reserved.
//
#include "NN2.hpp"
#include "InputIntermediaire.hpp"
#include <iostream>
#include <string>
using namespace std;


NN2::NN2()
{
}

NN2::~NN2()
{
}

/**
 @param inputSize : un entier correspondant Ã  la taille des inputs (par exemple 4 pour les fleurs et 784 pour les images)
 @param nbrCategorie : entier correspondant au nombre de catÃ©gories (et donc le nombre de perceptrons de la couche de sortie)
 @param nbrPerceptronC : entier correspondant au nombre de perceptrons dans la couche cachÃ©e
 */
NN2::NN2(int inputSize, int nbrCategorie, int nbrPerceptronC, FonctionActivation * f)
{
    if (inputSize != 4 && inputSize != 784) {
        throw string("Erreur : Taille de l input incorrect");
    }
    else {
        if (nbrCategorie != 10 && nbrCategorie != 3) {
            throw string("Erreur : Categorie nombre");
        }
        else {
            this->nbrPerceptron = nbrCategorie;
            this->nbrPerceptroncachee = nbrPerceptronC;
            
            this->lstPerceptron = new Perceptron[nbrPerceptron];
            this->lstPerceptronCachee = new PerceptronCachee[nbrPerceptronC];
            
            /* Initalise la liste des Perceptrons */
            for (int indice = 0; indice < nbrPerceptron; indice++) {
                Perceptron p = Perceptron(inputSize, f, indice);
                this->lstPerceptron[indice] = p;
            }
            
            /* Initalise la liste des Perceptrons Cachee
             Pour les perceptrons de la couche cachÃ©e, la label (qui nâ€™aura pas vraiment le sens de catÃ©gorie)
             correspondra Ã  lâ€™indice du perceptron dans le vecteur.
            */
            for (int indice = 0; indice < nbrPerceptronC; indice++) {
                vector<Perceptron> couche_sortie =  vector<Perceptron>();
                PerceptronCachee p = PerceptronCachee(inputSize, f, indice, couche_sortie);
                this->lstPerceptronCachee[indice] = p;
            }
        }
    }
}

/**
 @param input : indice par rÃ©fÃ©rence
 @brief Une fonction evaluation qui prend en paramÃ¨tre un Input (de prÃ©fÃ©rence une rÃ©fÃ©rence), et
 qui renvoie son label (char dont la valeur est comprise entre 0 et ğ‘Ÿ âˆ’ 1) Ã©valuÃ© en
 recherchant la plus grande valeur retournÃ©e par un des perceptrons de la couche de sortie.
 Lâ€™Ã©valuation des perceptrons de la couche cachÃ©e sera effectuÃ©e en premier, avec comme
 entrÃ©e lâ€™input. Par la suite, lâ€™input intermÃ©diaire sera donnÃ© en entrÃ©e des perceptrons de la couche de sortie, et
 la catÃ©gorie retournÃ©e sera celle du perceptron de la couche de sortie qui a la plus grande valeur.
 */
char NN2::evaluation(Input & input)
{
    // Un InputIntermÃ©diaire (correspondant Ã  ğ’‚(ğŸ) = (ğ‘1(1), â€¦ , ğ‘ğ‘¡(1))) sera crÃ©Ã© en
    // ajoutant la valeur de chaque perceptron de la couche cachÃ©e Ã  cet input intermÃ©diaire.
    InputIntermediaire inputInter(input.get_label());
    
    // lâ€™input intermÃ©diaire est donnÃ© en entrÃ©e des perceptrons de la couche de sortie grace a la fonction .forward()
    for (int i = 0; i < this->nbrPerceptroncachee; i++) {
        double valeur = this->lstPerceptronCachee[i].forward(inputInter);
        inputInter.add(valeur);
    }
    // la catÃ©gorie retournÃ©e est celle du perceptron de la couche de sortie qui a la plus grande valeur.
    double max = 0;
    int maxIndice = 0;
    double valeur = 0;
    for (int i = 0; i < this->nbrPerceptron; i++) {
        valeur = this->lstPerceptron[i].forward(inputInter);
        if (valeur > max) {
            max = valeur;
            maxIndice = i;
        }
    }
    return(to_string(maxIndice)[0]);
}

/**
@brief Une fonction apprentissage qui prend en paramÃ¨tre un Input (qui correspond Ã  (ğ’™ğ‘—, ğ‘¦ğ‘—)) et un double (correspondant au pas de gradient ğœ‡) et qui va appliquer lâ€™algorithme dâ€™apprentissage pour cet input. Il suffit dâ€™appliquer lâ€™algorithme d' "evaluation()".
Les valeurs ğ›¿ğ‘™(2) et ğ›¿ğ‘ (1) sont ensuite calculÃ©es (dans cet ordre) en faisant appel Ã  la fonction membre calcul_delta des perceptrons de la couche de sortie (avec comme
paramÃ¨tre lâ€™input intermÃ©diaire correspondant Ã  ğ’‚(ğŸ) = (ğ‘1(1), â€¦ , ğ‘ğ‘¡(1))) et la fonction membre calcul_delta des perceptrons de la couche cachÃ©e (avec comme paramÃ¨tre ğ’™ğ‘—).
AprÃ¨s cette Ã©tape, la fonction backprop de chaque perceptron de la couche cachÃ©e (avec comme paramÃ¨tre ğ’™ğ‘—) et la fonction backprop de chaque perceptron de la couche de sortie (avec comme paramÃ¨tre lâ€™input intermÃ©diaire correspondant Ã  ğ’‚(ğŸ) = (ğ‘1(1), â€¦ , ğ‘ğ‘¡(1))) est appliquÃ©e pour mettre Ã  jours les poids
*/
void NN2::apprentissage(Input & input, double mu)
{
    // Initialisation
    // Un input intermÃ©diaire (correspondant Ã  ğ’‚(ğŸ) = (ğ‘1(1), â€¦ , ğ‘ğ‘¡(1))) est crÃ©Ã© de la mÃªme maniÃ¨re que dans la fonction membre evaluation.
    InputIntermediaire inputInter(input.get_label());
    
    
    
    for (int i = 0; i < this->nbrPerceptron; i++) {
        // Les valeurs ğ›¿ğ‘™(2) et ğ›¿ğ‘ (1) sont ensuite calculÃ©es en faisant appel Ã  la fonction membre calcul_delta des perceptrons de la couche de sortie avec comme paramÃ¨tre ğ’™ğ‘—
        this->lstPerceptron[i].calcul_delta(inputInter);
        // La fonction backprop de chaque perceptron de la couche cachÃ©e (avec comme paramÃ¨tre ğ’™ğ‘—) et la fonction backprop de chaque perceptron de la couche de sortie (avec comme paramÃ¨tre lâ€™input intermÃ©diaire correspondant Ã  ğ’‚(ğŸ) = (ğ‘1(1), â€¦ , ğ‘ğ‘¡(1))) est appliquÃ©e pour mettre Ã  jours les poids
        this->lstPerceptron[i].backprop(inputInter, mu);
    }
    
    for (int i = 0; i < this->nbrPerceptroncachee; i++) {
        this->lstPerceptronCachee[i].calcul_delta(input);
        this->lstPerceptronCachee[i].backprop(input, mu);
    }

}
